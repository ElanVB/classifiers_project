{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a package that can plot graphics for us\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import a tool that will help us visualize the data\n",
    "from ipywidgets import interact\n",
    "\n",
    "# import the dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# import a package that will help us \"preprocess\" the data (name it understandable to our classifiers)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and see what it looks like.\n",
    "We can use the `interact` function to scroll through the images in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "def display_n(n):\n",
    "    digit_image = digits.images[n]\n",
    "    digit_label = digits.target[n]\n",
    "    \n",
    "    # Display the n-th digit\n",
    "    ## create a figure to plot on\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    ## set the title of the plot\n",
    "    plt.title(\"This is a {}\".format(digit_label))\n",
    "    \n",
    "    ## plot the digit as an image\n",
    "    plt.imshow(digit_image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    \n",
    "    ## remove the numbers on the axes\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    ## show the plot\n",
    "    plt.show()\n",
    "    \n",
    "# create a slider-bar that will let us scroll through and look at the images\n",
    "interact(display_n, n=(0, digits.images.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset contains images and a \"label\" (or target) for each image.\n",
    "This label tells us that this is an image of a eight (for example).\n",
    "We will need to use both the images and the labels to train our classifiers.\n",
    "\n",
    "Let's have a better look how the images are actually represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = digits.images.shape[0]\n",
    "print(\"There are {} images in the dataset.\".format(num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = len(digits.images[0].shape)\n",
    "print(\"Each image is stored in a {}-D array.\".format(num_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_shape = digits.images[0].shape\n",
    "print(\"The array the image is stored has a shape of {} (this is the size in each dimension).\".format(example_image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = digits.images[0]\n",
    "print(\"The array actually looks like this:\")\n",
    "print(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = digits.images.min()\n",
    "print(\"The minimum value in the images is '{}'.\".format(min_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = digits.images.max()\n",
    "print(\"The maximum value in the images is '{}'.\".format(max_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our images are stored in 2-D arrays and that the values in the arrays range from 0 to 16.\n",
    "\n",
    "We will need to change our data slightly so that our models will be able to learn from them:\n",
    "\n",
    "* flatten the images: some of our classifiers cannot learn from 2-D arrays, thus we will need to change all of our images to 1-D arrays;\n",
    "* zero-mean the images: subtract the average of the image from each pixel; and\n",
    "* normalize the images: scale our array to only contain values between -1 and 1.\n",
    "\n",
    "You may wonder why we are normalizing and zero-meaning the images.\n",
    "Machine learning models always work better with input values that range between -1 and 1.\n",
    "For a short explanation why, look [here](https://www.coursera.org/lecture/deep-neural-network/normalizing-inputs-lXv6U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "digits.images = digits.images.reshape(-1, 8*8)\n",
    "\n",
    "# double check\n",
    "num_dimensions = len(digits.images[0].shape)\n",
    "flat_image_length = digits.images[0].shape[0]\n",
    "print(\"All images are now {}-D arrays that are {} long.\".format(num_dimensions, flat_image_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-mean\n",
    "means = digits.images.mean(axis=0)\n",
    "digits.images -= means\n",
    "\n",
    "# double check\n",
    "print(\"The average of the data is '{}' (which is essensially zero).\".format(digits.images.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "# get min and max values\n",
    "min_values = digits.images.min(axis=0)\n",
    "max_values = digits.images.max(axis=0)\n",
    "\n",
    "# get the larges magnitudes\n",
    "max_magnitudes = np.maximum(max_values, np.abs(min_values))\n",
    "\n",
    "# check for zero's (as we cannot divide by zero) and set them to 1 (since dividing by 1 does nothing)\n",
    "max_magnitudes[max_magnitudes == 0] = 1\n",
    "\n",
    "# normalize the data\n",
    "digits.images /= max_magnitudes\n",
    "\n",
    "# double check\n",
    "min_value = digits.images.min()\n",
    "max_value = digits.images.max()\n",
    "print(\"The minimum value in the images is '{}' and the maximum is '{}'.\".format(min_value, max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = digits.images[0]\n",
    "print(\"Now the previous example image looks like this:\")\n",
    "print(example_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our input data (images) are ready for our model, we need to make sure our output data (the labels / targets) are also formatted in a way that our model will understand.\n",
    "\n",
    "Let's look at what the labels look like right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = digits.target.shape[0]\n",
    "print(\"There are {} labels / targets in the dataset.\".format(num_images))\n",
    "print(\"This makes sense since each image needs a label - so that we know what number / digit that image is.\")\n",
    "\n",
    "num_dimensions = len(digits.target[0].shape)\n",
    "print(\"Each label is stored in a {}-D array.\".format(num_dimensions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the labels are scalar values that are all stored in the 1-D array `digits.target`.\n",
    "\n",
    "Let's see what these scalars look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 100 labels\n",
    "print(digits.target[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the scalar value are the integer value corresponding to the number represented in the image.\n",
    "While it is possible to train a regression model to directly try output a continuous number and see what label it is closest to, this approach doesn't work very well and gives us no insight into how sure the model is of it's prediction.\n",
    "Instead, we train our models to output a probability for each label.\n",
    "For instance, Pr(label == 0 | image[0]) = 0.9; Pr(label == 1 | image[0]) = 0.01; ...\n",
    "and we put all of these predictions in an array and have our model give this as output:\n",
    "\n",
    "Model(image[0]) -> [Pr(label == 0 | image[0]), Pr(label == 1 | image[0]), ..., Pr(label == 9 | image[0])]\n",
    "\n",
    "Since we want our model to produce output in this form, we need to give it examples of output that is in this form.\n",
    "We need to change each scalar value into an array with the corresponding probability values.\n",
    "We call this new form the \"one-hot encoding\".\n",
    "\n",
    "The one-hot encoding for each digit is as follows:\n",
    "\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] (as we know this is a zero, so there is a probability of 1 for this label being zero and a probability of 0 for this label being something else)\n",
    "\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] (as we know this is a one, so there is a probability of 1 for this label being one and a probability of 0 for this label being something else)\n",
    "\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] (...)\n",
    "\n",
    "3 -> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] (...)\n",
    "\n",
    "4 -> [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] (...)\n",
    "\n",
    "5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] (...)\n",
    "\n",
    "6 -> [0, 0, 0, 0, 0, 0, 1, 0, 0, 0] (...)\n",
    "\n",
    "7 -> [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] (...)\n",
    "\n",
    "8 -> [0, 0, 0, 0, 0, 0, 0, 0, 1, 0] (...)\n",
    "\n",
    "9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] (...)\n",
    "\n",
    "This is how you create a one-hot encoding of the labels using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2-D array to store all the one-hot encodings\n",
    "one_hot_labels = np.zeros((num_labels, 10))\n",
    "\n",
    "# set all the corresponding values to 1\n",
    "one_hot_labels[np.arange(num_labels), digits.target] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will leave it as an exercise for you to figure out how and why this works.\n",
    "\n",
    "Let's have a look at what our one-hot encodings look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 labels and corresponding one-hot encodings\n",
    "print(digits.target[:10])\n",
    "print(one_hot_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that it is working properly.\n",
    "\n",
    "Now we need to divide our data into training, test and validation sets.\n",
    "The first thing we need to do is make sure that each set has some examples of each and that the data is in no particular order (if the data is in some order, the model might learn this pattern and think that it will always be present and this is not necessarily the case - there are also other reasons for doing this).\n",
    "We can achieve both of these by shuffling the data.\n",
    "But, remember that we need to shuffle both the images and the one-hot encodings in a way that they still match and if we shuffle both arrays individually, this will almost certainly not be the case.\n",
    "This is how I suggest going about the shuffling process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(digits.images.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_images = digits.images[shuffled_indices]\n",
    "shuffled_labels = one_hot_labels[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should do it, let's make sure they all still match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_preprocessed(n):\n",
    "    image = shuffled_images[n].reshape((8, 8))\n",
    "    label = np.argmax(shuffled_labels[n])\n",
    "    \n",
    "    # Display the n-th digit\n",
    "    ## create a figure to plot on\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    ## set the title of the plot\n",
    "    plt.title(\"This is a {}\".format(label))\n",
    "    \n",
    "    ## plot the digit as an image\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    \n",
    "    ## remove the numbers on the axes\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    ## show the plot\n",
    "    plt.show()\n",
    "\n",
    "# create a slider-bar\n",
    "interact(display_preprocessed, n=(0, shuffled_images.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the images look a little different than before, this is ok and expected.\n",
    "The important thing is that we can see that the labels do still match the images.\n",
    "\n",
    "Now it is time to split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_index = int(num_images * 0.8)\n",
    "train_input = shuffled_images[ : train_split_index]\n",
    "train_output = shuffled_labels[ : train_split_index]\n",
    "\n",
    "test_split_index = int(num_images * 0.9)\n",
    "test_input = shuffled_images[train_split_index : test_split_index]\n",
    "test_output = shuffled_labels[train_split_index : test_split_index]\n",
    "\n",
    "validation_input = shuffled_images[test_split_index : ]\n",
    "validation_output = shuffled_labels[test_split_index : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this split correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} images in our training set.\".format(train_input.shape[0]))\n",
    "print(\"There are {} images in our test set.\".format(test_input.shape[0]))\n",
    "print(\"There are {} images in our validation set.\".format(validation_input.shape[0]))\n",
    "\n",
    "print(\"There are {} labels in our training set.\".format(train_output.shape[0]))\n",
    "print(\"There are {} labels in our test set.\".format(test_output.shape[0]))\n",
    "print(\"There are {} labels in our validation set.\".format(validation_output.shape[0]))\n",
    "\n",
    "print(\"There are {} images in total.\".format(train_input.shape[0] + test_input.shape[0] + validation_input.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, it all works out.\n",
    "Now that we have gone through all the effort of formatting our data for our model, let's save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_input\", train_input)\n",
    "np.save(\"train_output\", train_output)\n",
    "\n",
    "np.save(\"test_input\", test_input)\n",
    "np.save(\"test_output\", test_output)\n",
    "\n",
    "np.save(\"validation_input\", validation_input)\n",
    "np.save(\"validation_output\", validation_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
